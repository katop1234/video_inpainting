{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/home/katop1234/.pyenv/versions/3.9.7/bin/python' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/home/katop1234/.pyenv/versions/3.9.7/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "import imageio\n",
    "import numpy as np\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from torchvision.transforms import ToTensor\n",
    "from moviepy.editor import concatenate_videoclips, VideoFileClip\n",
    "import cv2\n",
    "\n",
    "### HELPERS ###\n",
    "def image_to_tensor(file_path):\n",
    "    # Open the image using PIL\n",
    "    img = Image.open(file_path)\n",
    "\n",
    "    # Apply the ToTensor transform\n",
    "    tensor = ToTensor()(img)\n",
    "\n",
    "    return tensor\n",
    "\n",
    "def tensor_to_avi(tensor, output_path, fps=30):\n",
    "    ''' THIS IS FOR AVI ITS BUGGY SO FORGET IT EVEN THOUGH ITS LOSSLESS'''\n",
    "    assert output_path.endswith(\".avi\"), \"Output path must end with '.avi' so that it's lossless\"\n",
    "\n",
    "    # Create a list to store numpy arrays representing the images\n",
    "    images = []\n",
    "\n",
    "    # Convert each frame in the tensor to a PIL image and then to a numpy array\n",
    "    for i in range(tensor.shape[0]):\n",
    "        img = to_pil_image(tensor[i])\n",
    "        images.append(np.array(img))\n",
    "\n",
    "    # Save the list of numpy arrays as a lossless video using the FFV1 codec\n",
    "    imageio.mimwrite(output_path, images, fps=fps, codec='ffv1')\n",
    "\n",
    "def tensor_to_mp4(video_tensor, output_path):\n",
    "    # Convert the tensor to a numpy array\n",
    "    video_np = video_tensor.numpy()\n",
    "\n",
    "    # Rescale the pixel values to the range [0, 255]\n",
    "    video_np = (255 * video_np).astype('uint8')\n",
    "\n",
    "    # Transpose the tensor to match the shape expected by imageio (frames, height, width, channels)\n",
    "    video_np = video_np.transpose((0, 2, 3, 1))\n",
    "\n",
    "    # Write the frames to an MP4 file using imageio\n",
    "    with imageio.get_writer(output_path, fps=30) as writer:\n",
    "        for frame in video_np:\n",
    "            writer.append_data(frame)\n",
    "\n",
    "def normalize_tensor(tensor):\n",
    "    # Ensures values are bounded between 0 and 1\n",
    "    return (tensor - tensor.min()) / (tensor.max() - tensor.min())\n",
    "\n",
    "def concat_video_files(file1, file2, output_file):\n",
    "    assert os.path.exists(file1)\n",
    "    assert os.path.exists(file2)\n",
    "    \n",
    "    # Load the video files\n",
    "    clip1 = VideoFileClip(file1)\n",
    "    clip2 = VideoFileClip(file2)\n",
    "\n",
    "    # Concatenate the videos\n",
    "    final_clip = concatenate_videoclips([clip1, clip2])\n",
    "\n",
    "    # Write the concatenated video to the output file\n",
    "    final_clip.write_videofile(output_file)\n",
    "\n",
    "def save_frames(frames, video_fn, fps=30):\n",
    "    writer = imageio.get_writer(video_fn,fps=fps)\n",
    "    for frame in frames:\n",
    "        writer.append_data((frame).astype('uint8'))\n",
    "    writer.close()\n",
    "\n",
    "def detensorize(frames):\n",
    "    if len(frames.shape) == 5:\n",
    "        N, T, C, H, W = frames.shape\n",
    "        frames = frames.view((N * T, C, H, W))\n",
    "    return frames.cpu().squeeze(0).permute((0, 2, 3, 1)).numpy() * 255\n",
    "\n",
    "def tensorize(frames, device_id=0):\n",
    "    frames = torch.from_numpy(frames) / 255.\n",
    "    # B (T C H W) \n",
    "    return frames.permute((0, 3, 1, 2)).to(f'cuda:{device_id}')\n",
    "\n",
    "def load_frames_imageio(video_fn, start=0, stop=float('inf')):\n",
    "    reader = imageio.get_reader(video_fn)\n",
    "    frames = []\n",
    "    for i, frame in enumerate(reader):\n",
    "        if i == stop:\n",
    "            break\n",
    "        if i >= start:\n",
    "            frames.append(frame)\n",
    "    fps = reader.get_meta_data()['fps']\n",
    "    reader.close()\n",
    "    frames = np.stack(frames)\n",
    "    return frames, fps\n",
    "\n",
    "def concat_videos(*videos):\n",
    "    return np.concatenate(videos, axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DAVIS ###\n",
    "segmentation_folder = \"/data/katop1234/mae_testing_data/DAVIS/Annotations/\"\n",
    "RGB_folder = \"/data/katop1234/mae_testing_data/DAVIS/JPEGImages/\"\n",
    "output_dir = \"/data/katop1234/mae_testing_data/DAVIS/final_temporal_videos/\"\n",
    "videos_list = []\n",
    "\n",
    "for video_label in os.listdir(RGB_folder):\n",
    "    videos_list.append(video_label)\n",
    "\n",
    "### Temporal ###\n",
    "for video_label in videos_list:\n",
    "    if video_label + \".mp4\" not in os.listdir(output_dir):\n",
    "\n",
    "        print(\"Using label\", video_label)\n",
    "        segmented_video_folder = os.path.join(segmentation_folder, video_label)\n",
    "        RGB_video_folder = os.path.join(RGB_folder, video_label)\n",
    "        assert(len(os.listdir(segmented_video_folder)) == len(os.listdir(RGB_video_folder))), \"Number of files in segmented vs RGB folder must be equal\"\n",
    "        \n",
    "        RGB_frames = []\n",
    "        segmented_frames = []\n",
    "        home_dir = os.getcwd()\n",
    "        \n",
    "        rgb_images = [os.path.join(RGB_video_folder, f) for f in sorted(os.listdir(RGB_video_folder))]\n",
    "        RGB_frames = np.stack([imageio.imread(image_file) for image_file in rgb_images], axis=0)\n",
    "        \n",
    "        segmented_images = [os.path.join(segmented_video_folder, f) for f in sorted(os.listdir(segmented_video_folder))]\n",
    "\n",
    "        segmented_frames = []\n",
    "        for image_file in segmented_images:\n",
    "            seg_image_np_array = imageio.imread(image_file)\n",
    "            if len(seg_image_np_array.shape) == 2:\n",
    "                \n",
    "                print(\"all black seg file at\", image_file, \"got shape and array\", seg_image_np_array.shape, seg_image_np_array)\n",
    "                seg_image_np_array = np.repeat(seg_image_np_array[:, :, np.newaxis], 4, axis=2)\n",
    "\n",
    "            # Note, I removed the 4th channel for transparency. It doesn't matter since it's a black background anyway. \n",
    "            segmented_frames.append(seg_image_np_array[:, :, :3])\n",
    "        segmented_frames = np.stack(segmented_frames, axis=0)\n",
    "\n",
    "        final_video_path = os.path.join(output_dir, video_label + \".mp4\")\n",
    "\n",
    "        print(\"rgb shape\", RGB_frames.shape)\n",
    "        print(\"seg shape\", segmented_frames.shape)\n",
    "\n",
    "        concated_videos = concat_videos(RGB_frames, segmented_frames)\n",
    "        save_frames(concated_videos, final_video_path, 30)\n",
    "\n",
    "### Spatial ###\n",
    "output_dir = \"/data/katop1234/mae_testing_data/DAVIS/final_spatiotemporal_videos/\"\n",
    "for video_label in videos_list:\n",
    "    if video_label + \"_spatial.mp4\" not in os.listdir(output_dir):\n",
    "\n",
    "        print(\"Using label\", video_label)\n",
    "        segmented_video_folder = os.path.join(segmentation_folder, video_label)\n",
    "        RGB_video_folder = os.path.join(RGB_folder, video_label)\n",
    "        assert(len(os.listdir(segmented_video_folder)) == len(os.listdir(RGB_video_folder))), \"Number of files in segmented vs RGB folder must be equal\"\n",
    "        \n",
    "        RGB_frames = []\n",
    "        segmented_frames = []\n",
    "        home_dir = os.getcwd()\n",
    "        \n",
    "        rgb_images = [os.path.join(RGB_video_folder, f) for f in sorted(os.listdir(RGB_video_folder))]\n",
    "        RGB_frames = np.stack([imageio.imread(image_file) for image_file in rgb_images], axis=0)\n",
    "        \n",
    "        segmented_images = [os.path.join(segmented_video_folder, f) for f in sorted(os.listdir(segmented_video_folder))]\n",
    "\n",
    "        segmented_frames = []\n",
    "        for image_file in segmented_images:\n",
    "            seg_image_np_array = imageio.imread(image_file)\n",
    "            if len(seg_image_np_array.shape) == 2:\n",
    "                \n",
    "                print(\"all black seg file at\", image_file, \"got shape and array\", seg_image_np_array.shape, seg_image_np_array)\n",
    "                seg_image_np_array = np.repeat(seg_image_np_array[:, :, np.newaxis], 3, axis=2)\n",
    "\n",
    "            segmented_frames.append(seg_image_np_array[:, :, :3])\n",
    "        segmented_frames = np.stack(segmented_frames, axis=0)\n",
    "\n",
    "        final_video_path = os.path.join(output_dir, video_label + \"_spatial.mp4\")\n",
    "\n",
    "        print(\"rgb shape\", RGB_frames.shape)\n",
    "        print(\"seg shape\", segmented_frames.shape)\n",
    "\n",
    "        # Spatial concatenation\n",
    "        concated_videos = np.concatenate((RGB_frames, segmented_frames), axis=1)\n",
    "        save_frames(concated_videos, final_video_path, 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using label soldier\n",
      "rgb shape (32, 224, 528, 3)\n",
      "seg shape (32, 224, 528, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (259, 654) to (272, 656) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using label birdfall\n",
      "rgb shape (30, 327, 259, 3)\n",
      "seg shape (30, 327, 259, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[swscaler @ 0x6176b40] Warning: data is not aligned! This can lead to a speed loss\n",
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (480, 540) to (480, 544) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using label monkey\n",
      "rgb shape (31, 270, 480, 3)\n",
      "seg shape (31, 270, 480, 3)\n",
      "Using label frog\n",
      "rgb shape (279, 264, 480, 3)\n",
      "seg shape (279, 264, 480, 3)\n",
      "Using label girl\n",
      "rgb shape (21, 320, 400, 3)\n",
      "seg shape (21, 320, 400, 3)\n",
      "Using label drift\n",
      "rgb shape (74, 360, 640, 3)\n",
      "seg shape (74, 360, 640, 3)\n",
      "Using label bird_of_paradise\n",
      "rgb shape (98, 360, 640, 3)\n",
      "seg shape (98, 360, 640, 3)\n",
      "Using label bmx\n",
      "rgb shape (36, 360, 640, 3)\n",
      "seg shape (36, 360, 640, 3)\n",
      "Using label parachute\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (414, 704) to (416, 704) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rgb shape (51, 352, 414, 3)\n",
      "seg shape (51, 352, 414, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[swscaler @ 0x5f2cb40] Warning: data is not aligned! This can lead to a speed loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using label worm\n",
      "rgb shape (243, 264, 480, 3)\n",
      "seg shape (243, 264, 480, 3)\n",
      "Using label monkeydog\n",
      "rgb shape (71, 240, 320, 3)\n",
      "seg shape (71, 240, 320, 3)\n",
      "Using label hummingbird\n",
      "rgb shape (28, 360, 640, 3)\n",
      "seg shape (28, 360, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "### SegTrack ###\n",
    "segmentation_folder = \"/data/katop1234/mae_testing_data/segtrack/SegTrackv2/GroundTruth/\"\n",
    "RGB_folder = \"/data/katop1234/mae_testing_data/segtrack/SegTrackv2/JPEGImages/\"\n",
    "output_dir = \"/data/katop1234/mae_testing_data/segtrack/final_videos/\"\n",
    "videos_list = []\n",
    "\n",
    "bad_labels = [\"penguin\", \"cheetah\"]\n",
    "# both has .bmp idk wat to do with that\n",
    "\n",
    "for video_label in os.listdir(RGB_folder):\n",
    "    videos_list.append(video_label)\n",
    "\n",
    "### Temporal ###\n",
    "for video_label in videos_list:\n",
    "    if video_label + \".mp4\" not in os.listdir(output_dir) and video_label not in bad_labels:\n",
    "\n",
    "        print(\"Using label\", video_label)\n",
    "        segmented_video_folder = os.path.join(segmentation_folder, video_label)\n",
    "        RGB_video_folder = os.path.join(RGB_folder, video_label)\n",
    "        assert(len(os.listdir(segmented_video_folder)) == len(os.listdir(RGB_video_folder))), \"Number of files in segmented vs RGB folder must be equal\"\n",
    "        \n",
    "        RGB_frames = []\n",
    "        segmented_frames = []\n",
    "        home_dir = os.getcwd()\n",
    "        \n",
    "        rgb_images = [os.path.join(RGB_video_folder, f) for f in sorted(os.listdir(RGB_video_folder))]\n",
    "        RGB_frames = np.stack([imageio.imread(image_file) for image_file in rgb_images], axis=0)\n",
    "\n",
    "        segmented_images = [os.path.join(segmented_video_folder, f) for f in sorted(os.listdir(segmented_video_folder))]\n",
    "\n",
    "        segmented_frames = []\n",
    "        for image_file in segmented_images:\n",
    "            seg_image_np_array = imageio.imread(image_file)\n",
    "            segmented_frames.append(seg_image_np_array)\n",
    "        segmented_frames = np.stack(segmented_frames, axis=0)\n",
    "\n",
    "        final_video_path = os.path.join(output_dir, video_label + \".mp4\")\n",
    "\n",
    "        print(\"rgb shape\", RGB_frames.shape)\n",
    "        print(\"seg shape\", segmented_frames.shape)\n",
    "\n",
    "        concated_videos = concat_videos(RGB_frames, segmented_frames)\n",
    "        save_frames(concated_videos, final_video_path, 30)\n",
    "\n",
    "### Spatial ###\n",
    "output_dir = \"/data/katop1234/mae_testing_data/segtrack/final_videos/\"\n",
    "for video_label in videos_list:\n",
    "    if video_label + \"_spatial.mp4\" not in os.listdir(output_dir) and video_label not in bad_labels:\n",
    "\n",
    "        print(\"Using label\", video_label)\n",
    "        segmented_video_folder = os.path.join(segmentation_folder, video_label)\n",
    "        RGB_video_folder = os.path.join(RGB_folder, video_label)\n",
    "        assert(len(os.listdir(segmented_video_folder)) == len(os.listdir(RGB_video_folder))), \"Number of files in segmented vs RGB folder must be equal\"\n",
    "        \n",
    "        RGB_frames = []\n",
    "        segmented_frames = []\n",
    "        home_dir = os.getcwd()\n",
    "        \n",
    "        rgb_images = [os.path.join(RGB_video_folder, f) for f in sorted(os.listdir(RGB_video_folder))]\n",
    "        RGB_frames = np.stack([imageio.imread(image_file) for image_file in rgb_images], axis=0)\n",
    "        \n",
    "        segmented_images = [os.path.join(segmented_video_folder, f) for f in sorted(os.listdir(segmented_video_folder))]\n",
    "\n",
    "        segmented_frames = []\n",
    "        for image_file in segmented_images:\n",
    "            seg_image_np_array = imageio.imread(image_file)\n",
    "            if len(seg_image_np_array.shape) == 2:\n",
    "                \n",
    "                print(\"all black seg file at\", image_file, \"got shape and array\", seg_image_np_array.shape, seg_image_np_array)\n",
    "                seg_image_np_array = np.repeat(seg_image_np_array[:, :, np.newaxis], 3, axis=2)\n",
    "\n",
    "            segmented_frames.append(seg_image_np_array[:, :, :3])\n",
    "        segmented_frames = np.stack(segmented_frames, axis=0)\n",
    "\n",
    "        final_video_path = os.path.join(output_dir, video_label + \"_spatial.mp4\")\n",
    "\n",
    "        print(\"rgb shape\", RGB_frames.shape)\n",
    "        print(\"seg shape\", segmented_frames.shape)\n",
    "\n",
    "        # Spatial concatenation\n",
    "        concated_videos = np.concatenate((RGB_frames, segmented_frames), axis=1)\n",
    "        save_frames(concated_videos, final_video_path, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
